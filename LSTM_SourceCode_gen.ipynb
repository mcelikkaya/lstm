{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "In this code, I try to generate Java code by LSTM\n",
    "Code is loading Java codes from some sources and combine them.\n",
    "Than code is made a sequence of 50 keywords to yield 51th item.\n",
    "I put some println(s) to show intermediate outputs.\n",
    "Selected training java codes are more core library codes,\n",
    "so selecting a code written for a real life code will look different.\n",
    "'''\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1345\n",
      "2408\n",
      "4993\n",
      "7332\n",
      "9012\n"
     ]
    }
   ],
   "source": [
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r',encoding=\"utf-8\")\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "def process_file(file_name):\n",
    "    doc = load_doc(file_name)\n",
    "    lines = doc.split('\\n')\n",
    "    cleaned = []\n",
    "    invalids = [\"/\",\"*\"]\n",
    "    for i in range(len(lines)):\n",
    "        orig = lines[i].strip()\n",
    "        #print(orig,len(orig))    \n",
    "        if len(orig) > 3  :\n",
    "            if orig[0] not in invalids :\n",
    "                cleaned.append(orig.lower())\n",
    "    return cleaned\n",
    "    \n",
    "def process_files(files):\n",
    "    combined = process_file('D:/data2/java_codes/'+files[0])\n",
    "    for j in range(1,len(files)):\n",
    "        print(len(combined))\n",
    "        combined.extend(  process_file('D:/data2/java_codes/'+files[j]))\n",
    "    return combined    \n",
    "    \n",
    "#just get some random files from Java source codes\n",
    "all_files = process_files([\"Arrays.txt\",\"BigInteger.txt\",\"Character.txt\",\"Collections.txt\",\"Formatter.txt\"])\n",
    "print(len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['public class arrays {',\n",
       " 'private static final int min_array_sort_gran = 1 << 13;',\n",
       " 'private arrays() {}',\n",
       " 'static final class naturalorder implements comparator<object> {',\n",
       " '@suppresswarnings(\"unchecked\")',\n",
       " 'public int compare(object first, object second) {',\n",
       " 'return ((comparable<object>)first).compareto(second);',\n",
       " 'static final naturalorder instance = new naturalorder();',\n",
       " 'private static void rangecheck(int arraylength, int fromindex, int toindex) {',\n",
       " 'if (fromindex > toindex) {']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1st 10 lines\n",
    "all_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words 61925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'public class arrays { private static final int min_array_sort_gran ='"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seperate ( ) + ,  keywords\n",
    "corpus = []\n",
    "for s in all_files:\n",
    "    splits = s.replace(\")\",\" ) \").replace(\"(\",\" ( \").replace(\";\",\" ; \").replace(\",\",\" , \").strip().split(\" \")\n",
    "    for k in splits:        \n",
    "        if len(k.strip()) > 0:\n",
    "            #print(k.strip())\n",
    "            corpus.extend([k.strip()])\n",
    "            \n",
    "print(\"total words = \",len(corpus))    \n",
    "#print 1st 10 keywords\n",
    "' '.join(corpus[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 61925\n",
      "Unique Tokens: 5024\n",
      "Total Sequences: 61874\n"
     ]
    }
   ],
   "source": [
    "tokens = corpus\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))\n",
    " \n",
    "# organize into sequences of tokens\n",
    "length = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "\t# select sequence of tokens\n",
    "\tseq = tokens[i-length:i]\n",
    "\t# convert into a line\n",
    "\tline = ' '.join(seq)\n",
    "\t# store\n",
    "\tsequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['public class arrays { private static final int min_array_sort_gran = 1 << 13 ; private arrays ( ) {} static final class naturalorder implements comparator<object> { @suppresswarnings ( \"unchecked\" ) public int compare ( object first , object second ) { return ( ( comparable<object> ) first ) .compareto ( second',\n",
       " 'class arrays { private static final int min_array_sort_gran = 1 << 13 ; private arrays ( ) {} static final class naturalorder implements comparator<object> { @suppresswarnings ( \"unchecked\" ) public int compare ( object first , object second ) { return ( ( comparable<object> ) first ) .compareto ( second )']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "sequences2 = tokenizer.texts_to_sequences(sequences)\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword =  public class arrays { private static final int min_array_sort_gran = 1 << 13 ; private arrays ( ) {} static final class naturalorder implements comparator<object> { @suppresswarnings ( \"unchecked\" ) public int compare ( object first , object second ) { return ( ( comparable<object> ) first ) .compareto ( second\n",
      " \n",
      "encoded =  [7, 82, 5017, 5, 19, 9, 14, 10, 111, 6, 25, 113, 1065, 3, 19, 5017, 1, 2, 1064, 9, 14, 82, 1412, 110, 5013, 5, 92, 1, 116, 2, 7, 10, 843, 1, 41, 327, 4, 41, 736, 2, 5, 8, 1, 1, 1411, 2, 327, 2, 1063, 1, 736]\n"
     ]
    }
   ],
   "source": [
    "#print some\n",
    "i = 0\n",
    "print(\"keyword = \",sequences[i])\n",
    "print(\" \")\n",
    "print(\"encoded = \",sequences2[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences2 (61874, 51)\n"
     ]
    }
   ],
   "source": [
    "sequences2 = np.array(sequences2)\n",
    "print(\"sequences2\",sequences2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61874, 50)\n",
      "(61874,)\n"
     ]
    }
   ],
   "source": [
    "X, y = sequences2[:,:-1], sequences2[:,-1]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   7   82 5017    5   19    9   14   10  111    6   25  113 1065    3\n",
      "    19 5017    1    2 1064    9   14   82 1412  110 5013    5   92    1\n",
      "   116    2    7   10  843    1   41  327    4   41  736    2    5    8\n",
      "     1    1 1411    2  327    2 1063    1]\n",
      " [  82 5017    5   19    9   14   10  111    6   25  113 1065    3   19\n",
      "  5017    1    2 1064    9   14   82 1412  110 5013    5   92    1  116\n",
      "     2    7   10  843    1   41  327    4   41  736    2    5    8    1\n",
      "     1 1411    2  327    2 1063    1  736]\n",
      " [5017    5   19    9   14   10  111    6   25  113 1065    3   19 5017\n",
      "     1    2 1064    9   14   82 1412  110 5013    5   92    1  116    2\n",
      "     7   10  843    1   41  327    4   41  736    2    5    8    1    1\n",
      "  1411    2  327    2 1063    1  736    2]]\n",
      "[736   2   3]\n"
     ]
    }
   ],
   "source": [
    "# 736   2   3 output sequence is 51,52 and 53 of the sequence\n",
    "print(X[0:3])\n",
    "print(y[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 50)            251250    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5025)              507525    \n",
      "=================================================================\n",
      "Total params: 909,675\n",
      "Trainable params: 909,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# separate into input and output\n",
    "\n",
    "\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]\n",
    " \n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "61874/61874 [==============================] - 108s 2ms/step - loss: 5.2875 - accuracy: 0.1091\n",
      "Epoch 2/50\n",
      "61874/61874 [==============================] - 102s 2ms/step - loss: 4.3665 - accuracy: 0.2127\n",
      "Epoch 3/50\n",
      "61874/61874 [==============================] - 154s 2ms/step - loss: 3.6263 - accuracy: 0.3670\n",
      "Epoch 4/50\n",
      "61874/61874 [==============================] - 163s 3ms/step - loss: 3.2513 - accuracy: 0.4247\n",
      "Epoch 5/50\n",
      "61874/61874 [==============================] - 184s 3ms/step - loss: 2.9906 - accuracy: 0.4579\n",
      "Epoch 6/50\n",
      "61874/61874 [==============================] - 194s 3ms/step - loss: 2.7360 - accuracy: 0.4893\n",
      "Epoch 7/50\n",
      "61874/61874 [==============================] - 204s 3ms/step - loss: 2.5168 - accuracy: 0.5180\n",
      "Epoch 8/50\n",
      "61874/61874 [==============================] - 201s 3ms/step - loss: 2.3528 - accuracy: 0.5374\n",
      "Epoch 9/50\n",
      "61874/61874 [==============================] - 292s 5ms/step - loss: 2.2094 - accuracy: 0.5538\n",
      "Epoch 10/50\n",
      "61874/61874 [==============================] - 100s 2ms/step - loss: 2.0802 - accuracy: 0.5686\n",
      "Epoch 11/50\n",
      "61874/61874 [==============================] - 103s 2ms/step - loss: 1.9587 - accuracy: 0.5843\n",
      "Epoch 12/50\n",
      "61874/61874 [==============================] - 122s 2ms/step - loss: 1.8537 - accuracy: 0.5999\n",
      "Epoch 13/50\n",
      "61874/61874 [==============================] - 116s 2ms/step - loss: 1.7637 - accuracy: 0.6121\n",
      "Epoch 14/50\n",
      "61874/61874 [==============================] - 135s 2ms/step - loss: 1.6722 - accuracy: 0.6256\n",
      "Epoch 15/50\n",
      "61874/61874 [==============================] - 171s 3ms/step - loss: 1.6038 - accuracy: 0.6371\n",
      "Epoch 16/50\n",
      "61874/61874 [==============================] - 291s 5ms/step - loss: 1.5217 - accuracy: 0.6483\n",
      "Epoch 17/50\n",
      "61874/61874 [==============================] - 250s 4ms/step - loss: 1.4480 - accuracy: 0.6605\n",
      "Epoch 18/50\n",
      "61874/61874 [==============================] - 185s 3ms/step - loss: 1.3775 - accuracy: 0.6725\n",
      "Epoch 19/50\n",
      "61874/61874 [==============================] - 138s 2ms/step - loss: 1.3137 - accuracy: 0.6825\n",
      "Epoch 20/50\n",
      "61874/61874 [==============================] - 122s 2ms/step - loss: 1.2536 - accuracy: 0.6926\n",
      "Epoch 21/50\n",
      "61874/61874 [==============================] - 96s 2ms/step - loss: 1.1979 - accuracy: 0.7020\n",
      "Epoch 22/50\n",
      "61874/61874 [==============================] - 99s 2ms/step - loss: 1.1426 - accuracy: 0.7142\n",
      "Epoch 23/50\n",
      "61874/61874 [==============================] - 104s 2ms/step - loss: 1.0943 - accuracy: 0.7216\n",
      "Epoch 24/50\n",
      "61874/61874 [==============================] - 108s 2ms/step - loss: 1.0464 - accuracy: 0.7317\n",
      "Epoch 25/50\n",
      "61874/61874 [==============================] - 117s 2ms/step - loss: 1.0010 - accuracy: 0.7420\n",
      "Epoch 26/50\n",
      "61874/61874 [==============================] - 115s 2ms/step - loss: 0.9550 - accuracy: 0.7500\n",
      "Epoch 27/50\n",
      "61874/61874 [==============================] - 117s 2ms/step - loss: 0.9166 - accuracy: 0.7579\n",
      "Epoch 28/50\n",
      "61874/61874 [==============================] - 1646s 27ms/step - loss: 0.8779 - accuracy: 0.7664\n",
      "Epoch 29/50\n",
      "61874/61874 [==============================] - 23938s 387ms/step - loss: 0.8436 - accuracy: 0.7736\n",
      "Epoch 30/50\n",
      "61874/61874 [==============================] - 117s 2ms/step - loss: 0.8059 - accuracy: 0.7835\n",
      "Epoch 31/50\n",
      "61874/61874 [==============================] - 114s 2ms/step - loss: 0.7749 - accuracy: 0.7906\n",
      "Epoch 32/50\n",
      "61874/61874 [==============================] - 106s 2ms/step - loss: 0.7467 - accuracy: 0.7952\n",
      "Epoch 33/50\n",
      "61874/61874 [==============================] - 119s 2ms/step - loss: 0.7174 - accuracy: 0.8039\n",
      "Epoch 34/50\n",
      "61874/61874 [==============================] - 168s 3ms/step - loss: 0.6869 - accuracy: 0.8091\n",
      "Epoch 35/50\n",
      "61874/61874 [==============================] - 206s 3ms/step - loss: 0.6570 - accuracy: 0.8173\n",
      "Epoch 36/50\n",
      "61874/61874 [==============================] - 340s 6ms/step - loss: 0.6313 - accuracy: 0.8246\n",
      "Epoch 37/50\n",
      "61874/61874 [==============================] - 381s 6ms/step - loss: 0.6091 - accuracy: 0.8288\n",
      "Epoch 38/50\n",
      "61874/61874 [==============================] - 189s 3ms/step - loss: 0.5876 - accuracy: 0.8333\n",
      "Epoch 39/50\n",
      "61874/61874 [==============================] - 164s 3ms/step - loss: 0.5655 - accuracy: 0.8395\n",
      "Epoch 40/50\n",
      "61874/61874 [==============================] - 168s 3ms/step - loss: 0.5428 - accuracy: 0.8451\n",
      "Epoch 41/50\n",
      "61874/61874 [==============================] - 133s 2ms/step - loss: 0.5253 - accuracy: 0.8492\n",
      "Epoch 42/50\n",
      "61874/61874 [==============================] - 132s 2ms/step - loss: 0.5023 - accuracy: 0.8563\n",
      "Epoch 43/50\n",
      "61874/61874 [==============================] - 166s 3ms/step - loss: 0.4814 - accuracy: 0.8601\n",
      "Epoch 44/50\n",
      "61874/61874 [==============================] - 191s 3ms/step - loss: 0.4643 - accuracy: 0.8651\n",
      "Epoch 45/50\n",
      "61874/61874 [==============================] - 191s 3ms/step - loss: 0.4490 - accuracy: 0.8690\n",
      "Epoch 46/50\n",
      "61874/61874 [==============================] - 233s 4ms/step - loss: 0.4389 - accuracy: 0.8716\n",
      "Epoch 47/50\n",
      "61874/61874 [==============================] - 241s 4ms/step - loss: 0.4220 - accuracy: 0.8766\n",
      "Epoch 48/50\n",
      "61874/61874 [==============================] - 271s 4ms/step - loss: 0.3995 - accuracy: 0.8825\n",
      "Epoch 49/50\n",
      "61874/61874 [==============================] - 216s 3ms/step - loss: 0.3882 - accuracy: 0.8854\n",
      "Epoch 50/50\n",
      "61874/61874 [==============================] - 219s 4ms/step - loss: 0.3725 - accuracy: 0.8897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x231f7932588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "# save the model to file\n",
    "#model.save('D:/data2/model_javcodes2.h5')\n",
    "# save the tokenizer\n",
    "#dump(tokenizer, open('D:/data2/tokenizer_javcodes2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_next(model, tokenizer, seq_length, seed_text):\n",
    "    reverse = dict([ (v,k) for k,v in tokenizer.word_index.items()])\n",
    "    encoded = tokenizer.texts_to_sequences([seed_text])\n",
    "    #get head element\n",
    "    encoded = encoded[0]\n",
    "    #pad with maxlen  \n",
    "    padded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "    #predict\n",
    "    yhat = model.predict_classes(padded, verbose=0)\n",
    "    return reverse[yhat[0]]\n",
    "\n",
    "def generate_batch(model, tokenizer, seq_length, seed_text, n_words):\n",
    "\tprint(\"seed_text\",seed_text)\n",
    "\tresult = list()\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = generate_next(model, tokenizer, seq_length,in_text)\n",
    "\t\t# append to input\n",
    "\t\tin_text += ' ' + out_word\n",
    "\t\t#print(\"in_text\",in_text)\n",
    "\t\tresult.append(out_word)\n",
    "\treturn ' '.join(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_text public class arrays\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'( char c ) { return forname0 ( name , initialize , loader ) ; private void getdeclaredclasses ( ) throws securityexception { checkmemberaccess ( member.declared , reflection.getcallerclass ( ) , true ) ; return getconstructor0 ( empty , flags ) ; @callersensitive public field getfield ( string name )'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_batch(model, tokenizer, seq_length, \"public class arrays\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded [[7, 82, 5017]]\n",
      "encoded <class 'list'>\n",
      "encoded [7, 82, 5017]\n",
      "padded (1, 50)\n",
      "yhat [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'('"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 1 iteration\n",
    "in_text = \"public class arrays\"\n",
    "encoded = tokenizer.texts_to_sequences([in_text])\n",
    "print(\"encoded\",encoded)\n",
    "print(\"encoded\",type(encoded[0]))\n",
    "encoded = encoded[0]\n",
    "print(\"encoded\",encoded)\n",
    "padded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "print(\"padded\",padded.shape)\n",
    "yhat = model.predict_classes(padded, verbose=0)\n",
    "print(\"yhat\",yhat)\n",
    "out_word = ''\n",
    "for word, index in tokenizer.word_index.items():\n",
    "\tif index == yhat:\n",
    "\t\tout_word = word\n",
    "\t\tbreak\n",
    "out_word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_text public class arrays\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'( char c ) { return forname0 ( name , initialize , loader ) ; private void getdeclaredclasses ( ) throws securityexception { checkmemberaccess ( member.declared , reflection.getcallerclass ( ) , true ) ; return getconstructor0 ( empty , flags ) ; @callersensitive public field getfield ( string name )'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_batch(model, tokenizer, seq_length, \"public class arrays\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_text static final class\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'unmodifiableentrysetspliterator<k , v> s ; final sortedmap<k , v> m ; final spliterator<map.entry<k , v>> s ; checkedqueue ( queue<e> queue , class<e> elementtype , class<t> mutex ) { super ( m , mutex ) ; sm = m ; public comparator<? super k> comparator ( ) { return sm.comparator'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_batch(model, tokenizer, seq_length, \"static final class\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_text public int compare\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'( bigdecimal value , locale l ) throws ioexception stringbuilder sb = new stringbuilder ( ) ; leadingsign ( sb , neg ) ; } else if ( c == conversion.general ) { int prec = ( precision == doubleconsts.min_exponent - 1 ) ; int len = precision ; if'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_batch(model, tokenizer, seq_length, \"public int compare\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
